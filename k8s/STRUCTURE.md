# Structure du projet k8s/

## ğŸ“ Organisation des fichiers

```
k8s/
â”œâ”€â”€ ğŸ“‚ base/                              # Ressources communes aux deux environnements
â”‚   â”œâ”€â”€ auction-deployment.yaml           # DÃ©ploiement gRPC auction service
â”‚   â”œâ”€â”€ carrental-deployment.yaml         # DÃ©ploiement REST backend
â”‚   â”œâ”€â”€ frontend-deployment.yaml          # DÃ©ploiement Angular frontend
â”‚   â”œâ”€â”€ istio-internal-gateway.yaml       # Gateway/VirtualService/DestinationRule Istio
â”‚   â”œâ”€â”€ kustomization.yaml                # Configuration Kustomize base
â”‚   â”œâ”€â”€ namespace.yaml                    # Namespace rental-service
â”‚   â”œâ”€â”€ postgres-secret.yaml              # Secrets PostgreSQL
â”‚   â””â”€â”€ postgres-statefulset.yaml         # StatefulSet PostgreSQL
â”‚
â”œâ”€â”€ ğŸ“‚ overlays/
â”‚   â”œâ”€â”€ ğŸ“‚ kind/                          # Configuration spÃ©cifique Kind
â”‚   â”‚   â”œâ”€â”€ ingress-kind.yaml            # 5 Ingress (frontend, api, direct-api, subdomain, grpc)
â”‚   â”‚   â”œâ”€â”€ kustomization.yaml           # Kustomize overlay Kind
â”‚   â”‚   â””â”€â”€ patches/
â”‚   â”‚       â””â”€â”€ service-nodeport.yaml    # Patches services (actuellement vide)
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“‚ minikube/                      # Configuration spÃ©cifique Minikube
â”‚       â”œâ”€â”€ ingress-minikube.yaml        # 3 Ingress (frontend, api, direct-api)
â”‚       â””â”€â”€ kustomization.yaml           # Kustomize overlay Minikube
â”‚
â”œâ”€â”€ ğŸ“„ deploy.sh                          # Script dÃ©ploiement auto-dÃ©tection Kind/Minikube
â”œâ”€â”€ ğŸ“„ setup-kind-cluster.sh              # Script setup complet cluster Kind
â”œâ”€â”€ ğŸ“„ setup-minikube-cluster.sh          # Script setup complet cluster Minikube
â”œâ”€â”€ ğŸ“„ monitor.sh                         # Script monitoring (sans Istio)
â”œâ”€â”€ ğŸ“„ monitor-istio.sh                   # Script monitoring avec Istio
â”‚
â”œâ”€â”€ ğŸ“„ kind-config.yaml                   # Config Kind cluster (3 nÅ“uds + port mapping)
â”œâ”€â”€ ğŸ“„ kind-config-simple.yaml            # Config Kind cluster (simple, 1 nÅ“ud)
â”‚
â”œâ”€â”€ ğŸ“„ KUSTOMIZE.md                       # Documentation Kustomize
â””â”€â”€ ğŸ“„ README.md                          # Documentation principale (Istio + Ingress)
```

## ğŸ“Š Ressources dÃ©ployÃ©es

### Base (communes aux 2 environnements)
- âœ… 1 Namespace (rental-service)
- âœ… 1 Secret (postgres-credentials)
- âœ… 4 Services (postgres, carrental-service, auction-service, frontend-service)
- âœ… 1 StatefulSet (postgres)
- âœ… 3 Deployments (carrental, frontend-angular, auction-service-server) - **1 replica each**
- âœ… 1 Gateway Istio (rental-internal-gateway)
- âœ… 1 VirtualService Istio (carrental-internal-vs)
- âœ… 1 DestinationRule Istio (carrental-destination)
- âœ… 1 PeerAuthentication Istio (default-mtls PERMISSIVE)

### Overlay Kind
- âœ… 5 Ingress NGINX
  - frontend-ingress (/)
  - backend-api-ingress (/api/*)
  - backend-direct-api-ingress (/direct-api/*)
  - api-subdomain-ingress (api.car-rental.local)
  - grpc-ingress (grpc.car-rental.local)

### Overlay Minikube
- âœ… 3 Ingress NGINX
  - frontend-ingress (/)
  - backend-api-ingress (/api/*)
  - backend-direct-api-ingress (/direct-api/*)

## ğŸš€ Setup complet (depuis zÃ©ro)

### Option 1: Setup automatique Kind
```bash
cd k8s
./setup-kind-cluster.sh    # CrÃ©e cluster + Istio + NGINX + MetalLB
./deploy.sh                 # DÃ©ploie l'application
```

### Option 2: Setup automatique Minikube
```bash
cd k8s
./setup-minikube-cluster.sh  # CrÃ©e cluster + Istio + addons

# Build des images dans le Docker de Minikube
eval $(minikube docker-env)
docker build -f carRental/Dockerfile -t carrental:latest .
docker build -f auctionServiceServer/Dockerfile -t auction-service-server:latest .
docker build -f car-rental-angular/Dockerfile -t car-rental-angular:latest .

# Patcher Ingress en LoadBalancer pour le tunnel
kubectl patch svc ingress-nginx-controller -n ingress-nginx -p '{"spec":{"type":"LoadBalancer"}}'

minikube tunnel              # Dans un autre terminal
./deploy.sh                  # DÃ©ploie l'application
```

## ğŸš€ Commandes de dÃ©ploiement (cluster dÃ©jÃ  existant)

```bash
# DÃ©ploiement automatique (dÃ©tecte l'environnement)
./deploy.sh

# DÃ©ploiement manuel Kind
kubectl apply -k overlays/kind

# DÃ©ploiement manuel Minikube
kubectl apply -k overlays/minikube

# Tester la gÃ©nÃ©ration sans appliquer
kubectl kustomize overlays/kind
kubectl kustomize overlays/minikube
```

## ğŸ” DiffÃ©rences Kind vs Minikube

| Aspect | Kind | Minikube |
|--------|------|----------|
| **Ingress** | 5 Ingress (tous les chemins) | 3 Ingress (essentiels) |
| **AccÃ¨s** | localhost:80 via port mapping | 127.0.0.1:80 via tunnel + LoadBalancer |
| **NGINX** | Installation manuelle + patch control-plane | Addon intÃ©grÃ© (NodePort par dÃ©faut) |
| **Control-Plane** | NGINX doit tourner sur control-plane pour accÃ©der au port mapping | N/A |
| **Hosts** | 127.0.0.1 car-rental.local | 127.0.0.1 car-rental.local |
| **Images** | imagePullPolicy: Never | imagePullPolicy: IfNotPresent |
| **Build** | kind load docker-image | eval $(minikube docker-env) |
| **Replicas** | 1 per deployment | 1 per deployment |
| **Probes** | initialDelaySeconds: 120s (liveness), 90s (readiness) | Same |
| **LoadBalancer** | Not needed (port mapping) | Required patch for Ingress controller |

## ğŸ”§ Configuration Istio

Tous les pods d'application (sauf postgres) exÃ©cutent **2 containers** :
- Container principal de l'application
- Sidecar Istio Envoy (istio-proxy)

**Postgres est exclu** de l'injection Istio via l'annotation `sidecar.istio.io/inject: "false"` et ne contient qu'**1 container**.

Configuration partagÃ©e :
- âœ… Gateway Istio pour le routage interne
- âœ… VirtualService avec retry (3 tentatives, 10s) et timeout (30s API, 5s health)
- âœ… DestinationRule avec LEAST_REQUEST load balancing et circuit breaker
- âœ… PeerAuthentication en mode PERMISSIVE (mTLS optionnel)
- âœ… Label `istio-injection=enabled` sur namespace rental-service
- âœ… Annotation `sidecar.istio.io/inject: "false"` sur postgres StatefulSet

**Counts de containers attendus:**
- carRental: 2/2 (carrental + istio-proxy)
- frontend: 2/2 (frontend-angular + istio-proxy)
- auction: 2/2 (auction-service-server + istio-proxy)
- postgres: 1/1 (postgres uniquement, pas de sidecar)

## ğŸ·ï¸ Architecture des Labels

### Kustomize commonLabels et RÃ©Ã©criture

Les fichiers `kustomization.yaml` dÃ©finissent `commonLabels: app=rental-service` qui est appliquÃ© Ã  **toutes les ressources**. Cependant, Kustomize rÃ©Ã©crit les labels des pod templates, ce qui cause des problÃ¨mes avec les sÃ©lecteurs de services.

**ProblÃ¨me:** Si un deployment dÃ©finit `app: carrental` dans son pod template, Kustomize le change en `app: rental-service`.

**Solution:** Utiliser des labels dÃ©diÃ©s qui ne seront pas rÃ©Ã©crits :

```yaml
# Pod template d'un deployment
metadata:
  labels:
    app: rental-service          # RÃ©Ã©crit par commonLabels (attendu)
    service-name: carrental       # NON rÃ©Ã©crit - utilisÃ© par le sÃ©lecteur de service
    component: backend            # NON rÃ©Ã©crit - utilisÃ© pour kubectl wait
```

### StratÃ©gie de SÃ©lection des Services

Les services utilisent le label `service-name` pour sÃ©lectionner leurs pods :

```yaml
# carrental-service.yaml
spec:
  selector:
    service-name: carrental    # Match le label service-name dans le pod template
```

**Valeurs service-name disponibles:**
- `carrental` - Backend carRental
- `frontend` - Frontend Angular
- `auction` - Service auction
- `postgres` - Base de donnÃ©es PostgreSQL

### SÃ©lecteurs BasÃ©s sur component pour les OpÃ©rations

Pour les commandes `kubectl wait` et les tÃ¢ches opÃ©rationnelles, utiliser le label `component` :

```bash
# Attendre les pods backend
kubectl wait --for=condition=ready pod -l component=backend -n rental-service --timeout=600s

# Attendre les pods frontend
kubectl wait --for=condition=ready pod -l component=frontend -n rental-service --timeout=300s

# Attendre la base de donnÃ©es
kubectl wait --for=condition=ready pod -l component=database -n rental-service --timeout=300s
```

**Valeurs component disponibles:**
- `backend` - Services carRental et auction
- `frontend` - Frontend Angular
- `database` - PostgreSQL

## ğŸ”„ Pipeline CI/CD

Le projet inclut un pipeline CI/CD complet GitHub Actions (`.github/workflows/ci.yml`) :

### Ã‰tapes du Pipeline

1. **Build**
   - JDK 17 + Node.js 20
   - Gradle: `:carRental:bootJar`, `:auctionServiceServer:bootJar`
   - npm: build Angular frontend

2. **Docker**
   - Build images: carrental, auction-service-server, car-rental-angular
   - Contexte root avec flag `-f` pour les services Java
   - Tag `latest`

3. **Setup Cluster**
   - Kind cluster (nom: `kind`)
   - Istio installation
   - NGINX Ingress + patch control-plane
   - MetalLB pour LoadBalancer

4. **DÃ©ploiement**
   - `kind load docker-image` pour charger les images
   - ExÃ©cution de `deploy.sh` (mÃªme workflow que local)
   - Utilisation de `kubectl rollout status`

5. **VÃ©rification**
   - Injection sidecars Istio avec labels `service-name`
   - Counts containers: 2/2 pour apps, 1/1 pour postgres
   - Test API: `curl -H "Host: car-rental.local" http://localhost:80/api/offers`

6. **Cleanup**
   - Capture des logs
   - Suppression du cluster Kind

### Configurations ClÃ©s CI

```bash
# Nom du cluster
kind create cluster  # Utilise "kind" par dÃ©faut

# Chargement des images
kind load docker-image carrental:latest auction-service-server:latest car-rental-angular:latest

# VÃ©rification avec service-name labels
kubectl get pods -n rental-service -l service-name=carrental

# Attente avec component labels
kubectl wait --for=condition=ready pod -l component=backend -n rental-service --timeout=600s
```

### NGINX Control-Plane Patch (Critique pour Kind)

```bash
# AprÃ¨s installation NGINX, patch pour tourner sur control-plane
kubectl patch deployment ingress-nginx-controller -n ingress-nginx -p '{
  "spec": {
    "template": {
      "spec": {
        "nodeSelector": {"ingress-ready": "true"},
        "tolerations": [
          {"key": "node-role.kubernetes.io/control-plane", "operator": "Equal", "effect": "NoSchedule"},
          {"key": "node-role.kubernetes.io/master", "operator": "Equal", "effect": "NoSchedule"}
        ]
      }
    }
  }
}'
```

**Raison:** Le port mapping Kind (80:80, 443:443) est configurÃ© sur le nÅ“ud control-plane. NGINX doit y tourner pour accÃ©der Ã  localhost.

## âœ… Validation
- âœ… Kustomize base contient 8 ressources
- âœ… Overlay Kind gÃ©nÃ¨re 19 ressources totales
- âœ… Overlay Minikube gÃ©nÃ¨re 17 ressources totales
- âœ… Pas de fichiers en double
- âœ… Tous les fichiers obsolÃ¨tes supprimÃ©s
